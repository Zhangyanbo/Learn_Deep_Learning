{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “火炬上的深度学习\"第一次大作业\n",
    "\n",
    "在这个作业中，你需要半独立地利用人工神经网络搭建一个手写数字识别器\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"简单的 LeNet-5类型的卷积神经网络模型，MNIST例子.\n",
    "\"\"\"\n",
    "\n",
    "#所有依赖包\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#定义一系列常数\n",
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/' #图像数据如果没下载，可以从这个地址下载\n",
    "WORK_DIRECTORY = 'data' #存储的路径名\n",
    "IMAGE_SIZE = 28 #每张图片的大小尺寸\n",
    "NUM_CHANNELS = 1  #每张图片的通道数\n",
    "PIXEL_DEPTH = 255 #像素的深度0-255\n",
    "NUM_LABELS = 10 #手写数字，一共十种\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取MINST图形文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#下载图像文件，如果文件已经存在，那么就不下载。\n",
    "def maybe_download(filename):\n",
    "    \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "    if not os.path.isdir(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        size = os.path.getsize(filepath)\n",
    "        print('Successfully downloaded', filename, size, 'bytes.')\n",
    "    return filepath\n",
    "# Get the data.\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    # filename: 文件存放的路径，num_images: 读入的图片个数\n",
    "    \"\"\"将图像解压缩展开，读入成一个4维的张量： [image index（图像的编码）, y（纵坐标）, x（横坐标）, channels（通道）].\n",
    "    我们将数组中的数值范围从原来的[0, 255]降低到了[-0.5, 0.5]范围内\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"将label的数据文件解压缩，并将label读成64位的整数\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels\n",
    "\n",
    "# 将数据解压缩并存储到数组中，60000张图片，60000个label，测试集中有10000张图片\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_X = train_data.reshape(len(train_data), -1)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "train_Y = train_labels\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_X = test_data.reshape(len(test_data), -1)\n",
    "\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "test_Y = test_labels\n",
    "train_X.shape, train_Y.shape\n",
    "\n",
    "# train_X, train_Y 中分别存储的是向量化的训练数据与标签\n",
    "# test_X, test_Y 中分别存储的是向量化的测试数据与标签\n",
    "# train_X的维度是60000个样本，784个分量的图像向量\n",
    "# test_X的维度是10000个样本，784个分量的图像向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在这里写下你自己的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一步：定义神经网络，提示，可以使用简单的torch.nn.SequentialModel\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 提示：需要考虑好网络有几层，每一层有多少个节点\n",
    "#net = torch.nn.Sequential(\n",
    "#    torch.nn.Linear(784, 10),\n",
    "#    torch.nn.Sigmoid(),\n",
    "#)\n",
    "\n",
    "# 问题：如果要增加新的神经网络层怎么办？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二步：构造损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cost = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三步：开始训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3233\n",
      "100 0.0671661\n",
      "200 0.0359067\n",
      "300 0.0221188\n",
      "400 0.0147049\n",
      "500 0.0104579\n",
      "600 0.00785325\n",
      "700 0.00616211\n",
      "800 0.00499631\n",
      "900 0.00416906\n"
     ]
    }
   ],
   "source": [
    "# 提示：有两重循环，最外面层是多少次的训练，里层为对数据批次（batch）的循环\n",
    "\n",
    "\n",
    "# 神经网络训练循环\n",
    "#batch_size = 128\n",
    "#for i in range(1000):\n",
    "    # 每128个样本点被划分为一个撮，在循环的时候一撮一撮地读取\n",
    "#    batch_loss = []\n",
    "    # start和end分别是提取一个batch数据的起始和终止下标\n",
    "#    for start in range(0, len(train_X), batch_size):\n",
    "#        end = start + batch_size if start + batch_size < len(train_X) else len(train_X)\n",
    "#        xx = Variable(torch.FloatTensor(train_X[start:end])) #从训练数据train_X中提取数据\n",
    "#        yy = Variable(torch.LongTensor(train_Y[start:end]))  #从训练数据train_Y中提取标签，注意标签数据为整数，因此相应的tensor也要为long\n",
    "#        predict = neuc(xx) #用神经网络进行预测\n",
    "#        loss = cost(predict, yy) #计算损失函数（交叉熵）\n",
    "#        optimizer.zero_grad() #清空梯度\n",
    "#        loss.back() #开始反向传播\n",
    "#        optimizer.step_() #开始更新梯度\n",
    "#        batch_loss.append(loss.data.numpy())\n",
    "    \n",
    "    # 每隔100步输出一下损失值（loss）\n",
    "#    if i % 100==0:\n",
    "#        print(i, np.mean(batch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 请在这里写下你自己的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 请绘制上面训练过程的损失函数曲线，以及'''错误率曲线'''！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四步：在测试集上测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一个专门计算分类错误率的函数，它的基本思想是，对于预测向量predictions的每一行，\n",
    "# 取最大的那个元素的下标，与标签labels中的元素做比较\n",
    "#def error_rate(predictions, labels):\n",
    "#    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，labels是数据之中的正确答案\"\"\"\n",
    "#    predictions = np.argmax(predictions, 1)\n",
    "#    return 100.0 - (\n",
    "#      100.0 *\n",
    "#      np.sum( predictions == labels) /\n",
    "#      predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分多个batch计算测试结果\n",
    "#errors = []\n",
    "#losses = []\n",
    "#i = 0\n",
    "#for start in range(0, len(test_X), batch_size):\n",
    "#    end1 = start + batch_size if start + batch_size < len(test_X) else len(test_X)\n",
    "#    i += 1\n",
    "#    x = Variable(torch.FloatTensor(test_X[start:end]))\n",
    "#    y = Variable(torch.FloatTensor(test_Y[start:end]))\n",
    "#    predictions = net(x)\n",
    "#    loss = cost(predictions, y)\n",
    "#    err_rate = error_rate(predictions.data.numpy(), y.data.numpy())\n",
    "#    errors.append(err_rate)\n",
    "#    losses.append(loss.data.numpy())\n",
    "#    print(i, err_rate)\n",
    "\n",
    "#print('平均错误率：%.4f%%'%np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用单个图像进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11af1ce80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ac076d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#随便从数据集中读入一张图片，并绘制出来\n",
    "#idx = 100\n",
    "#muteimg = test_data[idx, 0, :, :]\n",
    "#plt.imshow(muteimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算识别结果\n",
    "#x = Variable(torch.FloatTensor(test_X[idx, :].reshape(1, -1)))\n",
    "#predict = net(x)\n",
    "#np.argmax(predict.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 升级版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你已经运行跑通上面的所有代码，那么请你尝试对其进行更改，让测试集上面的识别错误率进一步下降，看看能不能到1%以下\n",
    "\n",
    "提示：可以考虑增加层的深度\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
